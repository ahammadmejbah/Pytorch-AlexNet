{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center> Alexnet -Deep Neuron AI </center><h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BONnTHsZT6VF",
    "outputId": "41b72c60-a5e2-4170-8ef1-4a65d287269b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1b0d8413650>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import pprint\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9F-6bPOEUh8h"
   },
   "outputs": [],
   "source": [
    "# AlexNet architecture (do not use this model.)\n",
    "class AlexNet(nn.Module):\n",
    "  def __init__(self, number_of_classes):\n",
    "    super(AlexNet, self).__init__()\n",
    "    self.feats = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=3, out_channels=64, kernel_size=11, stride=4, padding=5),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Conv2d(in_channels=64, out_channels=192, kernel_size=5, padding=2),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Conv2d(in_channels=192, out_channels=384, kernel_size=3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    )\n",
    "    self.clf = nn.Linear(in_features=256, out_features=number_of_classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    output = self.feats(input)\n",
    "    output = output.view(output.size(0), -1)\n",
    "    output = self.clf(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_MA1eQZrX-Vd",
    "outputId": "e7c5bfd5-dcf1-4e0d-83ac-4e492ef9704f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (feats): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(5, 5))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU()\n",
       "    (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (clf): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexNet = AlexNet(10)\n",
    "alexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MLgwIDreU0tx"
   },
   "source": [
    "Download the dataset from [kaggle](https://www.kaggle.com/ajayrana/hymenoptera-data). More information about the dataset can be found at [hymenoptera](https://hymenoptera.elsiklab.missouri.edu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "duEuiiGSceL7",
    "outputId": "08929e51-df19-413c-fa72-5a2103fee08c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'hymenoptera_data'\n",
    "!unzip /content/hymenoptera_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wu8QQbX-aVEW"
   },
   "outputs": [],
   "source": [
    "# data normalization and augumentation for train dataset\n",
    "# only normalization trnasformation for validatation dataset\n",
    "data_transforms = {\n",
    "  'train':\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.490, 0.449, 0.411], [0.231, 0.221, 0.230])\n",
    "    ]),\n",
    "  'val':\n",
    "    transforms.Compose([\n",
    "      transforms.Resize(256),\n",
    "      transforms.CenterCrop(224),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize([0.490, 0.449, 0.411], [0.231, 0.221, 0.230])\n",
    "    ])\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K9EBIplMcPrp",
    "outputId": "591cada8-1ad0-45b9-8189-885f94dd4198"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'hymenoptera_data\\\\train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16524\\4158605729.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m img_data = {\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_transforms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'val'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m }\n\u001b[0;32m      4\u001b[0m \u001b[0mpp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpprint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPrettyPrinter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16524\\4158605729.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m img_data = {\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_transforms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'val'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m }\n\u001b[0;32m      4\u001b[0m \u001b[0mpp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpprint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPrettyPrinter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeptorch\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m             \u001b[0mtarget_transform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m             \u001b[0mis_valid_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_valid_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m         )\n\u001b[0;32m    318\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeptorch\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m    143\u001b[0m     ) -> None:\n\u001b[0;32m    144\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m         \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeptorch\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    217\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \"\"\"\n\u001b[1;32m--> 219\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deeptorch\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mSee\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;32mclass\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \"\"\"\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'hymenoptera_data\\\\train'"
     ]
    }
   ],
   "source": [
    "img_data = {\n",
    "    key: datasets.ImageFolder(os.path.join(dataset_path, key), data_transforms[key]) for key in ['train', 'val']\n",
    "}\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "pp.pprint(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8mbr6ZJ_dFMd"
   },
   "outputs": [],
   "source": [
    "data_loaders = {\n",
    "    key: DataLoader(img_data[key], batch_size=8, shuffle=True, num_workers=0) for key in ['train', 'val'] \n",
    "  }\n",
    "datasets_size = {\n",
    "    key: len(img_data[key]) for key in ['train', 'val']\n",
    "} \n",
    "classes = img_data['train'].classes\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sL8eY8crdTV3",
    "outputId": "2fec770e-2d9f-4f68-a838-4a4cd27fd112"
   },
   "outputs": [],
   "source": [
    "pp.pprint(data_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dl2dhgRffN9M",
    "outputId": "74edb3a9-9311-4ff2-ba1a-95bfbfa6fad2"
   },
   "outputs": [],
   "source": [
    "pp.pprint(datasets_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s0KX_i4FfP9v",
    "outputId": "171cfc0e-e0c3-4c3b-daed-fbe01c0a9b41"
   },
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CLi4XsiWfRT0"
   },
   "outputs": [],
   "source": [
    "def choose_train_or_validation(model, dset):\n",
    "    if dset == 'train':\n",
    "        return model.train()  # set model to train mode (i.e. trainbale weights)\n",
    "    else:\n",
    "        return model.eval()   # set model to validation mode\n",
    "\n",
    "def finetune_model(pretrained_model, loss_func, optim, epochs=10):\n",
    "    \n",
    "    def train_validation(dset, imgs, tgts):\n",
    "        imgs = imgs.to(device)\n",
    "        tgts = tgts.to(device)\n",
    "        optim.zero_grad()\n",
    "        with torch.set_grad_enabled(dset == 'train'):\n",
    "            ops = pretrained_model(imgs)\n",
    "            _, preds = torch.max(ops, 1)\n",
    "            loss_curr = loss_func(ops, tgts)\n",
    "            # backward pass only if in training mode\n",
    "            if dset == 'train':\n",
    "                loss_curr.backward()\n",
    "                optim.step()\n",
    "        \n",
    "        b_loss = loss_curr.item() * imgs.size(0)\n",
    "        b_successes = torch.sum(preds == tgts.data)\n",
    "        return b_loss, b_successes\n",
    "\n",
    "    start = time.time()\n",
    "    best_model_weights = copy.deepcopy(pretrained_model.state_dict())\n",
    "    accuracy = 0.0\n",
    "    for e in range(epochs):\n",
    "        print(f'Epoch number {e}/{epochs - 1}')\n",
    "        print('=' * 20)\n",
    "        # for each epoch we run through the training and validation set\n",
    "        for dset in ['train', 'val']:\n",
    "            pretrained_model = choose_train_or_validation(pretrained_model, dset).to(device)\n",
    "            loss = 0.0\n",
    "            successes = 0\n",
    "            # iterate over the (training/validation) data.\n",
    "            for imgs, tgts in data_loaders[dset]:\n",
    "                batch_loss, batch_successe = train_validation(dset, imgs, tgts)\n",
    "                loss += batch_loss\n",
    "                successes += batch_successe\n",
    "            \n",
    "            loss_epoch = loss / datasets_size[dset]\n",
    "            accuracy_epoch = successes.double() / datasets_size[dset]\n",
    "\n",
    "            print(f'{dset} loss in this epoch: {loss_epoch}, accuracy in this epoch: {accuracy_epoch}')\n",
    "            if dset == 'val' and accuracy_epoch > accuracy:\n",
    "                accuracy = accuracy_epoch\n",
    "                best_model_weights = copy.deepcopy(pretrained_model.state_dict())\n",
    "\n",
    "    time_delta = time.time() - start\n",
    "    print(f'* Training finished in {time_delta // 60} mins {time_delta % 60} secs')\n",
    "    print(f'* Best validation set accuracy: {accuracy}')\n",
    "\n",
    "    # load the best model version (weights)\n",
    "    pretrained_model.load_state_dict(best_model_weights)\n",
    "    return pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "rEkgbsI5nCMC",
    "outputId": "2114c783-3e31-4ab2-fe2a-ba239942ddfd"
   },
   "outputs": [],
   "source": [
    "def imageshow(img, text=None):\n",
    "    img = img.numpy().transpose((1, 2, 0))\n",
    "    avg = np.array([0.490, 0.449, 0.411])\n",
    "    stddev = np.array([0.231, 0.221, 0.230])\n",
    "    img = stddev * img + avg\n",
    "    img = np.clip(img, 0, 1)\n",
    "    plt.imshow(img)\n",
    "    if text is not None:\n",
    "        plt.title(text)\n",
    "\n",
    "# Generate one train dataset batch\n",
    "imgs, cls = next(iter(data_loaders['train']))\n",
    "\n",
    "# Generate a grid from batch\n",
    "grid = torchvision.utils.make_grid(imgs)\n",
    "\n",
    "imageshow(grid, text=[classes[c] for c in cls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V3Lgk-oChvj7"
   },
   "outputs": [],
   "source": [
    "def visualize_predictions(pretrained_model, max_num_imgs=4):\n",
    "  torch.manual_seed(1)\n",
    "  was_model_training = pretrained_model.training\n",
    "  pretrained_model.eval()\n",
    "  imgs_counter = 0\n",
    "  fig = plt.figure()\n",
    "\n",
    "  with torch.no_grad():\n",
    "      for i, (imgs, labels) in enumerate(data_loaders['val']):\n",
    "          imgs = imgs.to(device)\n",
    "          labels = labels.to(device)\n",
    "          ops = pretrained_model(imgs)\n",
    "          _, preds = torch.max(ops, 1)\n",
    "          \n",
    "          for j in range(imgs.size()[0]):\n",
    "              imgs_counter += 1\n",
    "              ax = plt.subplot(max_num_imgs//2, 2, imgs_counter)\n",
    "              ax.axis('off')\n",
    "              ax.set_title(f'pred: {classes[preds[j]]} || target: {classes[labels[j]]}')\n",
    "              imageshow(imgs.cpu().data[j])\n",
    "\n",
    "              if imgs_counter == max_num_imgs:\n",
    "                  pretrained_model.train(mode=was_model_training)\n",
    "                  return\n",
    "      pretrained_model.train(mode=was_model_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GVvKnRX1hypg",
    "outputId": "f6e67381-57f1-4d8c-dd62-155930114e9a"
   },
   "outputs": [],
   "source": [
    "model_finetune = models.alexnet(pretrained=True)\n",
    "print(model_finetune.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tc5dnZ6Mh1Cj",
    "outputId": "49126ed6-aba1-4884-ce5d-2bf58ecbebc3"
   },
   "outputs": [],
   "source": [
    "print(model_finetune.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fLiLa0uCh2vH",
    "outputId": "352017ba-ca26-469c-a7f5-c18862996c0f"
   },
   "outputs": [],
   "source": [
    "# change the last layer from 1000 classes to 2 classes\n",
    "model_finetune.classifier[6] = nn.Linear(4096, len(classes))\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optim_finetune = opt.SGD(model_finetune.parameters(), lr=0.0001)\n",
    "\n",
    "# train (fine-tune) and validate the model\n",
    "model_finetune = finetune_model(model_finetune, loss_func, optim_finetune, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "jmiz-iC5h5j9",
    "outputId": "76414b8f-c98e-4753-9b25-9a493f3123ec"
   },
   "outputs": [],
   "source": [
    "visualize_predictions(model_finetune)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AlexNet Fine-tuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
